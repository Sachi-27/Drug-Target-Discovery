{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Protein_Encoder(nn.Module):\n",
    "    def __init__(self, input_feature_size, hidden_layers_size, num_hidden_layers, embedding_size):\n",
    "        super(Protein_Encoder, self).__init__()\n",
    "        self.input_feature_size = input_feature_size\n",
    "        self.hidden_layers_size = hidden_layers_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # input layer\n",
    "        self.linear_start = nn.Linear(self.input_feature_size, self.hidden_layers_size)\n",
    "        self.relu_start = nn.ReLU()\n",
    "        # hidden layers and relu activation\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.hidden_layers_size, self.hidden_layers_size) for i in range(self.num_hidden_layers)])\n",
    "        self.hidden_layers_activation = nn.ModuleList([nn.ReLU() for i in range(self.num_hidden_layers)])\n",
    "        # output layer\n",
    "        self.linear_end = nn.Linear(self.hidden_layers_size, self.embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_start(x)\n",
    "        x = self.relu_start(x)\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            x = self.hidden_layers[i](x)\n",
    "            x = self.hidden_layers_activation[i](x)\n",
    "        x = self.linear_end(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# PPI Predictor takes two protein embeddings and predicts the probability of interaction\n",
    "class PPI_Predictor(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_layers_size, num_hidden_layers):\n",
    "        super(PPI_Predictor, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_layers_size = hidden_layers_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        # input layer\n",
    "        self.linear_start = nn.Linear(2*self.embedding_size, self.hidden_layers_size)\n",
    "        self.relu_start = nn.ReLU()\n",
    "        # hidden layers and relu activation\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.hidden_layers_size, self.hidden_layers_size) for i in range(self.num_hidden_layers)])\n",
    "        self.hidden_layers_activation = nn.ModuleList([nn.ReLU() for i in range(self.num_hidden_layers)])\n",
    "        # output layer\n",
    "        self.linear_end = nn.Linear(self.hidden_layers_size, 1)\n",
    "        self.sigmoid_end = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_start(x)\n",
    "        x = self.relu_start(x)\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            x = self.hidden_layers[i](x)\n",
    "            x = self.hidden_layers_activation[i](x)\n",
    "        x = self.linear_end(x)\n",
    "        x = self.sigmoid_end(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# PPI Model combines the Protein Encoder and PPI Predictor\n",
    "class PPI_Model(nn.Module):\n",
    "    def __init__(self, input_feature_size, hidden_layers_size, num_hidden_layers, embedding_size):\n",
    "        super(PPI_Model, self).__init__()\n",
    "        self.protein_encoder = Protein_Encoder(input_feature_size, hidden_layers_size, num_hidden_layers, embedding_size)\n",
    "        self.ppi_predictor = PPI_Predictor(embedding_size, hidden_layers_size, num_hidden_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x[0]\n",
    "        x2 = x[1]\n",
    "        x1 = self.protein_encoder(x1)\n",
    "        x2 = self.protein_encoder(x2)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.ppi_predictor(x)\n",
    "        return x\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  json\n",
    "\n",
    "# Data Loader\n",
    "with open(\"../protein_properties/protein_props.json\", \"r\") as f:\n",
    "    protein_props = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345\n",
      "2652\n"
     ]
    }
   ],
   "source": [
    "druggable_data = \"../drugbank/druggable_proteins.txt\"\n",
    "with open(druggable_data) as f:\n",
    "  druggable_proteins = [line.strip() for line in f]\n",
    "print(len(druggable_proteins))\n",
    "\n",
    "approved_drugs = \"../drugbank/approved_druggable_proteins.txt\"\n",
    "with open(approved_drugs) as g:\n",
    "  approved_proteins = [line.strip() for line in g]\n",
    "print(len(approved_proteins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20434, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_props_data = {}\n",
    "for protein in protein_props:\n",
    "    feature_vector = []\n",
    "    feature_vector.append(protein_props[protein][\"Molecular Weight\"])\n",
    "    feature_vector.append(protein_props[protein][\"Sequence Length\"])\n",
    "    feature_vector.append(protein_props[protein][\"GRAVY\"])\n",
    "    for k, v in protein_props[protein][\"Amino Acid Percent\"].items():\n",
    "        feature_vector.append(v)\n",
    "    feature_vector.append(protein_props[protein][\"Molar Extinction Coefficient\"][0])\n",
    "    feature_vector.append(protein_props[protein][\"Molar Extinction Coefficient\"][1])\n",
    "    feature_vector.append(protein_props[protein][\"Isoelectric Point\"])\n",
    "    feature_vector.append(protein_props[protein][\"Aromaticity\"])\n",
    "    feature_vector.append(protein_props[protein][\"Instability Index\"])\n",
    "    for i in protein_props[protein][\"Secondary Structure\"]:\n",
    "        feature_vector.append(i)\n",
    "    protein_props_data[protein] = feature_vector\n",
    "\n",
    "len(protein_props_data), len(protein_props_data[\"P05067\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90606"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PPI data\n",
    "interaction_data = {}\n",
    "for protein in protein_props_data:\n",
    "    with open(f\"../PPIs/PPI_indiv/{protein}.json\", \"r\") as f:\n",
    "        interactions = json.load(f)\n",
    "    for interaction in interactions[protein]:\n",
    "        protein1 = interaction[\"entry1\"]\n",
    "        protein2 = interaction[\"entry2_id\"]\n",
    "        if (protein1, protein2) in interaction_data:\n",
    "            assert(interaction_data[(protein1, protein2)] == interaction[\"interaction_type\"])\n",
    "        elif (protein2, protein1) in interaction_data:\n",
    "            assert(interaction_data[(protein2, protein1)] == interaction[\"interaction_type\"])\n",
    "        else:\n",
    "            interaction_data[(protein1, protein2)] = interaction[\"interaction_type\"]\n",
    "        \n",
    "len(interaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3405, 87201)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of xeno interactions and binary interactions\n",
    "xeno_interactions = 0\n",
    "binary_interactions = 0\n",
    "for interaction in interaction_data:\n",
    "    if interaction_data[interaction] == \"xeno\":\n",
    "        xeno_interactions += 1\n",
    "    elif interaction_data[interaction] == \"binary\":\n",
    "        binary_interactions += 1\n",
    "\n",
    "xeno_interactions, binary_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60614"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "# if any of the proteins in not in protein_props_data, remove the interaction\n",
    "final_interaction_data = {}\n",
    "for interaction in interaction_data:\n",
    "    if interaction[0] in protein_props_data and interaction[1] in protein_props_data:\n",
    "        final_interaction_data[interaction] = interaction_data[interaction]\n",
    "\n",
    "interaction_data = final_interaction_data.copy()\n",
    "len(interaction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is PCFs of protein pairs, target is interaction type (3 classes -- 3 neurons in output layer) -- binary, xeno, none\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class PPI_Dataset(Dataset):\n",
    "    def __init__(self, protein_props_data, interaction_data, druggable_proteins, approved_proteins):\n",
    "        self.protein_props_data = protein_props_data\n",
    "        self.interaction_data = interaction_data\n",
    "        self.druggable_proteins = druggable_proteins\n",
    "        self.proteins = list(protein_props_data.keys())\n",
    "        self.non_druggable_proteins = [protein for protein in self.proteins if protein not in druggable_proteins]\n",
    "\n",
    "        self.protein_pairs = list(self.interaction_data.keys())\n",
    "        self.targets = [self.interaction_data[protein_pair] for protein_pair in self.protein_pairs]\n",
    "        self.target_dict = {\"binary\": 0, \"xeno\": 1, \"none\": 2}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.protein_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        protein1, protein2 = self.protein_pairs[idx]\n",
    "        protein1_data = self.protein_props_data[protein1]\n",
    "        protein2_data = self.protein_props_data[protein2]\n",
    "        target = self.target_dict[self.targets[idx]]\n",
    "        # tensorize\n",
    "        protein1_data = torch.tensor(protein1_data)\n",
    "        protein2_data = torch.tensor(protein2_data)\n",
    "        target = torch.tensor(target)\n",
    "        return (protein1_data, protein2_data), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48491, 12123)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train, Test split stratify and shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "protein_pairs = list(interaction_data.keys())\n",
    "targets = [interaction_data[protein_pair] for protein_pair in protein_pairs]\n",
    "protein_pairs, targets = shuffle(protein_pairs, targets, random_state=42)\n",
    "\n",
    "train_protein_pairs, test_protein_pairs, train_targets, test_targets = train_test_split(protein_pairs, targets, test_size=0.2, stratify=targets, random_state=42)\n",
    "\n",
    "len(train_protein_pairs), len(test_protein_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PPI_Dataset(protein_props_data, dict(zip(train_protein_pairs, train_targets)), druggable_proteins, approved_proteins)\n",
    "test_data = PPI_Dataset(protein_props_data, dict(zip(test_protein_pairs, test_targets)), druggable_proteins, approved_proteins)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 1, Loss: 0.0\n",
      "Validation Loss: 0.0\n",
      "Epoch 2, Loss: 0.0\n",
      "Validation Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = PPI_Model(31, 80, 3, 20)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        exit()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss}\")\n",
    "    # validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            val_loss += loss.item()\n",
    "    print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "model.save_model(\"PPI_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     output \u001b[38;5;241m=\u001b[39m model([torch\u001b[38;5;241m.\u001b[39mtensor(protein_props_data[random_protein_pair[\u001b[38;5;241m0\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mtensor(protein_props_data[random_protein_pair[\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(output))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m, in \u001b[0;36mPPI_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotein_encoder(x1)\n\u001b[1;32m     68\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotein_encoder(x2)\n\u001b[0;32m---> 69\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x1, x2), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     70\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mppi_predictor(x)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model([torch.tensor(protein_props_data[random_protein_pair[0]]).to(device), torch.tensor(protein_props_data[random_protein_pair[1]]).to(device)])\n",
    "    print(output)\n",
    "    print(torch.argmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
